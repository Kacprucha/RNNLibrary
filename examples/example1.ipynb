{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rnn (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Impute               \n",
    "using Statistics\n",
    "include(\"../src/activationFunctions.jl\")\n",
    "include(\"../src/networkFunctions.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2027×1 Matrix{Float64}:\n",
       " 68.0\n",
       " 67.0\n",
       " 67.0\n",
       " 65.0\n",
       " 66.0\n",
       " 65.0\n",
       " 69.0\n",
       " 76.0\n",
       " 83.0\n",
       " 85.0\n",
       "  ⋮\n",
       " 62.0\n",
       " 61.0\n",
       " 60.0\n",
       " 62.0\n",
       " 67.0\n",
       " 66.0\n",
       " 70.0\n",
       " 62.0\n",
       " 64.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a simple StandardScaler\n",
    "struct StandardScaler\n",
    "    mean::Vector{Float64}\n",
    "    std::Vector{Float64}\n",
    "end\n",
    "\n",
    "function fit_scaler(X::AbstractMatrix)\n",
    "    m = vec(mean(X, dims=1))\n",
    "    s = vec(std(X, dims=1))\n",
    "    return StandardScaler(m, s)\n",
    "end\n",
    "\n",
    "function transform(s::StandardScaler, X::AbstractMatrix)\n",
    "    # Replace zero std values with 1.0 to avoid division by zero.\n",
    "    std_adj = map(x -> x == 0 ? 1.0 : x, s.std)\n",
    "    return (X .- s.mean') ./ std_adj'\n",
    "end\n",
    "\n",
    "function fit_transform(X::AbstractMatrix)\n",
    "    s = fit_scaler(X)\n",
    "    return transform(s, X), s\n",
    "end\n",
    "\n",
    "# Read CSV file into a DataFrame.\n",
    "data = CSV.read(\"clean_weather.csv\", DataFrame)\n",
    "\n",
    "# Forward-fill missing values.\n",
    "data = Impute.locf(data)\n",
    "\n",
    "# Define column names.\n",
    "PREDICTORS = [\"tmax\", \"tmin\", \"rain\"]\n",
    "TARGET = \"tmax_tomorrow\"\n",
    "\n",
    "# Ensure that the predictor columns have no missing values.\n",
    "for col in PREDICTORS\n",
    "    data[!, col] = coalesce.(data[!, col], 0.0)\n",
    "end\n",
    "\n",
    "# Also coalesce the target column.\n",
    "data[!, TARGET] = coalesce.(data[!, TARGET], 0.0)\n",
    "\n",
    "# Extract the predictor columns as a Matrix using hcat.\n",
    "predictor_matrix = hcat([data[!, col] for col in PREDICTORS]...)\n",
    "\n",
    "# Apply standard scaling using the custom scaler.\n",
    "scaled_predictors, scaler = fit_transform(predictor_matrix)\n",
    "\n",
    "# (Optional) Reassign the scaled predictors back into the DataFrame.\n",
    "for (i, col) in enumerate(PREDICTORS)\n",
    "    data[!, col] = scaled_predictors[:, i]\n",
    "end\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "Random.seed!(0)\n",
    "\n",
    "# Split the data.\n",
    "n = nrow(data)\n",
    "idx1 = floor(Int, 0.7 * n)\n",
    "idx2 = floor(Int, 0.85 * n)\n",
    "\n",
    "train_data = data[1:idx1, :]\n",
    "valid_data = data[idx1+1:idx2, :]\n",
    "test_data  = data[idx2+1:end, :]\n",
    "\n",
    "# Extract predictors and target values as matrices.\n",
    "train_x = hcat([train_data[!, col] for col in PREDICTORS]...)\n",
    "train_y = reshape(train_data[:, TARGET], :, 1)\n",
    "\n",
    "valid_x = hcat([valid_data[!, col] for col in PREDICTORS]...)\n",
    "valid_y = reshape(valid_data[:, TARGET], :, 1)\n",
    "\n",
    "test_x = hcat([test_data[!, col] for col in PREDICTORS]...)\n",
    "test_y = reshape(test_data[:, TARGET], :, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train loss 64.72492676869594 valid loss 66.557450476798\n",
      "Epoch: 20 train loss 64.54096239402082 valid loss 66.37777159691505\n",
      "Epoch: 30 train loss 64.3539899583781 valid loss 66.19545646345601\n",
      "Epoch: 40 train loss 64.15842234807124 valid loss 66.00524076337211\n",
      "Epoch: 50 train loss 63.94855186236193 valid loss 65.80157451775185\n",
      "Epoch: 60 train loss 63.719574833904 valid loss 65.57948110602553\n",
      "Epoch: 70 train loss 63.469401457412374 valid loss 65.33641520669042\n",
      "Epoch: 80 train loss 63.1982773508188 valid loss 65.07240634707019\n",
      "Epoch: 90 train loss 62.90564793157505 valid loss 64.78701363540827\n",
      "Epoch: 100 train loss 62.588827554740185 valid loss 64.47742621283338\n",
      "Epoch: 110 train loss 62.24345020420786 valid loss 64.1387334086018\n",
      "Epoch: 120 train loss 61.86403240530246 valid loss 63.764517500405226\n",
      "Epoch: 130 train loss 61.44501922886782 valid loss 63.348006375977505\n",
      "Epoch: 140 train loss 60.98298589520002 valid loss 62.88471538652683\n",
      "Epoch: 150 train loss 60.479601377139446 valid loss 62.376259543680625\n",
      "Epoch: 160 train loss 59.94261930252419 valid loss 61.83195954339448\n",
      "Epoch: 170 train loss 59.382571578535256 valid loss 61.264681201638595\n",
      "Epoch: 180 train loss 58.80811807213033 valid loss 60.6844418402511\n",
      "Epoch: 190 train loss 58.22433304190549 valid loss 60.096438660969454\n",
      "Epoch: 200 train loss 57.63375701049228 valid loss 59.502901589293224\n",
      "Epoch: 210 train loss 57.037791796888605 valid loss 58.9049083288648\n",
      "Epoch: 220 train loss 56.437383560376865 valid loss 58.30315001125748\n",
      "Epoch: 230 train loss 55.833253256691165 valid loss 57.698168190437826\n",
      "Epoch: 240 train loss 55.225978081123294 valid loss 57.09042634623835\n",
      "Epoch: 250 train loss 54.61602858279047 valid loss 56.48033067242883\n"
     ]
    }
   ],
   "source": [
    "function square_elementwise(x::ReverseNode)\n",
    "    out_val = x.value .^ 2\n",
    "    out = ReverseNode(out_val)\n",
    "    push!(out.children, (x, δ -> δ .* (2 .* x.value)))\n",
    "    return out\n",
    "end\n",
    "\n",
    "function sum_r(x::ReverseNode)\n",
    "    s = sum(x.value)          \n",
    "    out = ReverseNode(s)\n",
    "    push!(out.children, (x, δ -> fill(δ, size(x.value))))\n",
    "    return out\n",
    "end\n",
    "\n",
    "function abs_r(x::ReverseNode)\n",
    "    out_val = abs.(x.value)\n",
    "    out = ReverseNode(out_val)\n",
    "    push!(out.children, (x, δ -> δ .* sign.(x.value)))  \n",
    "    return out\n",
    "end\n",
    "\n",
    "function mae_loss(y_true::ReverseNode, y_pred::ReverseNode)\n",
    "    diff = y_pred - y_true\n",
    "    abs_diff = abs_r(diff)\n",
    "    total_loss = sum_r(abs_diff)\n",
    "    n = length(y_true.value)\n",
    "    return total_loss / lift(n)\n",
    "end\n",
    "\n",
    "# Layer configuration (using dictionaries)\n",
    "layer_conf = [\n",
    "    Dict(\"type\" => \"input\", \"units\" => 3),\n",
    "    Dict(\"type\" => \"rnn\", \"hidden\" => 4, \"units\" => 1)\n",
    "]\n",
    "\n",
    "epochs = 250\n",
    "lr = 1e-5\n",
    "sequence_length = 7\n",
    "activation_function = \"tanh\"\n",
    "\n",
    "rnn_print(train_x, train_y, valid_x, valid_y, layer_conf, epochs, lr, sequence_length, activation_function, mae_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
