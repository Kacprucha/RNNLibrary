{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sigmoid (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JLD2        \n",
    "include(\"../src/networkFunctions.jl\")\n",
    "include(\"../src/ADLibrary/functions.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load(\"data_rnn/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"data_rnn/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "y_train = Float32.(y_train)\n",
    "X_test = load(\"data_rnn/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"data_rnn/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "y_test  = Float32.(y_test)\n",
    "embeddings = load(\"data_rnn/imdb_dataset_prepared.jld2\", \"embeddings\")\n",
    "vocab = load(\"data_rnn/imdb_dataset_prepared.jld2\", \"vocab\")\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition ---\n",
    "\n",
    "loss_fun(y_pred, y_true) = -mean(y_true .* log.(y_pred .+ 1e-7) .+ (1 .- y_true) .* log.(1 .- y_pred .+ 1e-7))\n",
    "\n",
    "vocab_size = length(vocab)\n",
    "embedding_dim = size(embeddings,1);\n",
    "hidden_size = 16\n",
    "\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, embedding_dim),\n",
    "  SimpleRNN(embedding_dim, hidden_size, ReLU), \n",
    "  SelectLastTimestep(),\n",
    "  Flatten(), \n",
    "  Dense(hidden_size, 1, Sigmoid)\n",
    "])\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ▶ Train Loss=0.693, Train Acc=50.83%\t│   Test Loss=0.6925, Test Acc=50.71%\t|   Time=28.87\n",
      "Epoch 2 ▶ Train Loss=0.6847, Train Acc=53.39%\t│   Test Loss=0.6914, Test Acc=51.57%\t|   Time=17.7\n",
      "Epoch 3 ▶ Train Loss=0.6533, Train Acc=56.62%\t│   Test Loss=0.682, Test Acc=54.83%\t|   Time=25.13\n",
      "Epoch 4 ▶ Train Loss=0.6164, Train Acc=58.23%\t│   Test Loss=0.7259, Test Acc=51.78%\t|   Time=25.19\n",
      "Epoch 5 ▶ Train Loss=0.5883, Train Acc=59.53%\t│   Test Loss=0.7506, Test Acc=52.17%\t|   Time=26.51\n",
      "Epoch 6 ▶ Train Loss=0.5712, Train Acc=62.37%\t│   Test Loss=0.7477, Test Acc=53.6%\t|   Time=21.71\n",
      "Epoch 7 ▶ Train Loss=0.4429, Train Acc=78.7%\t│   Test Loss=0.5165, Test Acc=80.49%\t|   Time=19.23\n",
      "Epoch 8 ▶ Train Loss=0.3576, Train Acc=85.76%\t│   Test Loss=0.4739, Test Acc=81.48%\t|   Time=18.88\n",
      "Epoch 9 ▶ Train Loss=0.3008, Train Acc=88.39%\t│   Test Loss=0.6023, Test Acc=81.94%\t|   Time=19.36\n",
      "Epoch 10 ▶ Train Loss=0.2815, Train Acc=89.96%\t│   Test Loss=0.4733, Test Acc=82.03%\t|   Time=19.29\n",
      "Epoch 11 ▶ Train Loss=0.2578, Train Acc=90.89%\t│   Test Loss=0.4943, Test Acc=82.36%\t|   Time=19.48\n",
      "Epoch 12 ▶ Train Loss=0.25, Train Acc=91.37%\t│   Test Loss=0.5, Test Acc=82.37%\t|   Time=19.78\n"
     ]
    }
   ],
   "source": [
    "train!(model, loss_fun, X_train, y_train, X_test, y_test; epochs=12, lr=0.001, batchsize=128, optimizer=:Adam, clip_norm=1.0f0, decay_factor=0.5f0, decay_epochs=4, print_learning_data=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1 sample with 1 evaluation per sample.\n",
       " Single result which took \u001b[34m193.878 s\u001b[39m (24.94% GC) to evaluate,\n",
       " with a memory estimate of \u001b[33m171.02 GiB\u001b[39m, over \u001b[33m294470343\u001b[39m allocations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, embedding_dim),\n",
    "  SimpleRNN(embedding_dim, hidden_size, ReLU), \n",
    "  SelectLastTimestep(),\n",
    "  Flatten(), \n",
    "  Dense(hidden_size, 1, Sigmoid)\n",
    "])\n",
    "\n",
    "@benchmark train!(model, loss_fun, X_train, y_train, X_test, y_test; epochs=12, lr=0.001, batchsize=128, optimizer=:Adam, clip_norm=1.0f0, decay_factor=0.5f0, decay_epochs=4, print_learning_data=false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
