{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46053002",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6555f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "X_train = load(\"../data/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../data/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../data/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../data/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "embeddings = load(\"../data/imdb_dataset_prepared.jld2\", \"embeddings\")\n",
    "vocab = load(\"../data/imdb_dataset_prepared.jld2\", \"vocab\")\n",
    "nothing\n",
    "\n",
    "embedding_dim = size(embeddings,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13aad85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Embedding(12849 => 50),               \u001b[90m# 642_450 parameters\u001b[39m\n",
       "  RNN(50 => 16, relu),                  \u001b[90m# 1_072 parameters\u001b[39m\n",
       "  var\"#11#12\"(),\n",
       "  Flux.flatten,\n",
       "  Dense(16 => 1, σ),                    \u001b[90m# 17 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m643_539 parameters, 2.455 MiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux, Random\n",
    "Random.seed!(0)\n",
    "\n",
    "model = Chain(\n",
    "    Flux.Embedding(length(vocab), embedding_dim),\n",
    "    Flux.RNN(embedding_dim => 16, relu, return_state = true),\n",
    "    x -> x[end],\n",
    "    Flux.flatten,\n",
    "    Dense(16, 1, σ)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b4a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Glove embeddings to Embedding layer\n",
    "model.layers[1].weight .= embeddings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2428538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_loop (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Printf, Statistics\n",
    "\n",
    "function train_loop(print=true)\n",
    "    dataset = Flux.DataLoader((X_train, y_train), batchsize=128, shuffle=true)\n",
    "\n",
    "    loss(m, x, y) = Flux.Losses.binarycrossentropy(m(x), y)\n",
    "    accuracy(m, x, y) = mean((m(x) .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "    opt = Optimisers.setup(RMSProp(), model)\n",
    "\n",
    "    epochs = 12\n",
    "    for epoch in 1:epochs\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        num_samples = 0\n",
    "\n",
    "        t = @elapsed begin\n",
    "            for (x, y) in dataset\n",
    "                Flux.reset!(model)\n",
    "                grads = Flux.gradient(model) do m\n",
    "                loss(m, x, y)\n",
    "                end\n",
    "                Optimisers.update!(opt, model, grads[1])\n",
    "                total_loss += loss(model, x, y)\n",
    "                total_acc += accuracy(model, x, y)\n",
    "                num_samples += 1\n",
    "            end\n",
    "\n",
    "            train_loss = total_loss / num_samples\n",
    "            train_acc = total_acc / num_samples\n",
    "\n",
    "            test_acc = accuracy(model, X_test, y_test)\n",
    "            test_loss = loss(model, X_test, y_test)\n",
    "        end\n",
    "\n",
    "        if print\n",
    "            println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\", \n",
    "                epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa59ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (63.43s) \tTrain: (l: 0.69, a: 0.52) \tTest: (l: 0.69, a: 0.50)\n",
      "Epoch: 2 (17.56s) \tTrain: (l: 0.68, a: 0.54) \tTest: (l: 0.69, a: 0.51)\n",
      "Epoch: 3 (14.69s) \tTrain: (l: 0.58, a: 0.70) \tTest: (l: 0.53, a: 0.75)\n",
      "Epoch: 4 (14.01s) \tTrain: (l: 0.47, a: 0.79) \tTest: (l: 0.53, a: 0.79)\n",
      "Epoch: 5 (14.61s) \tTrain: (l: 0.41, a: 0.83) \tTest: (l: 0.44, a: 0.82)\n",
      "Epoch: 6 (13.98s) \tTrain: (l: 0.37, a: 0.85) \tTest: (l: 0.39, a: 0.84)\n",
      "Epoch: 7 (14.08s) \tTrain: (l: 0.33, a: 0.87) \tTest: (l: 0.45, a: 0.83)\n",
      "Epoch: 8 (14.47s) \tTrain: (l: 0.31, a: 0.88) \tTest: (l: 0.39, a: 0.84)\n",
      "Epoch: 9 (14.55s) \tTrain: (l: 0.28, a: 0.90) \tTest: (l: 0.36, a: 0.85)\n",
      "Epoch: 10 (14.04s) \tTrain: (l: 0.26, a: 0.90) \tTest: (l: 0.39, a: 0.85)\n",
      "Epoch: 11 (15.26s) \tTrain: (l: 0.24, a: 0.91) \tTest: (l: 0.46, a: 0.85)\n",
      "Epoch: 12 (13.88s) \tTrain: (l: 0.23, a: 0.92) \tTest: (l: 0.36, a: 0.87)\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d8e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1 sample with 1 evaluation per sample.\n",
       " Single result which took \u001b[34m178.951 s\u001b[39m (14.64% GC) to evaluate,\n",
       " with a memory estimate of \u001b[33m154.19 GiB\u001b[39m, over \u001b[33m158204593\u001b[39m allocations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "Random.seed!(0)\n",
    "\n",
    "model = Chain(\n",
    "    Flux.Embedding(length(vocab), embedding_dim),\n",
    "    Flux.RNN(embedding_dim => 16, relu, return_state = true),\n",
    "    x -> x[end],\n",
    "    Flux.flatten,\n",
    "    Dense(16, 1, σ)\n",
    ")\n",
    "\n",
    "model.layers[1].weight .= embeddings;\n",
    "\n",
    "@benchmark train_loop(false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
